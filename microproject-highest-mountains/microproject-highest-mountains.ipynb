{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n",
    "<span style=\"\">MicroProject: Highest Mountains in the World</span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/highest-mountain/\">https://discovery.cs.illinois.edu/microproject/highest-mountain/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Source: Wikipedia's \"List of mountains by elevation\"\n",
    "\n",
    "Wikipedia is an absolutely amazing source of information about almost every topic you can imagine!  In this microproject, you will explore how to easily use data in Wikipedia tables as datasets.\n",
    "\n",
    "The Wikipedia article \"[List of mountains by elevation](https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)\" (https://en.wikipedia.org/wiki/List_of_mountains_by_elevation) contains information on hundreds of mountains -- including Mount Everest (tallest in the world), Denali (tallest in the United States), and many more!\n",
    "- Click the link above [(or right here)]((https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)\" (https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)) to view how the Wikipedia page looks in your web browser!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using pandas `read_html` function\n",
    "\n",
    "The `pd.read_html(...)` function in the pandas library is designed to read data from tables found in webpages.\n",
    "- `read_html` is very similar to the more commonly used `read_csv`\n",
    "- Instead of returning a DataFrame like `read_csv`, the `read_html` returns a **list of DataFrames** -- one DataFrame for each table!\n",
    "- Just like `read_csv`, you only need to provide the URL of the data!\n",
    "\n",
    "Import `pandas` and create a new variable called `pages` the reads in all of tables on the Wikipedia page  \"[List of mountains by elevation](https://en.wikipedia.org/wiki/List_of_mountains_by_elevation)\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = ...\n",
    "pages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Checkpoint Tests 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Data Import\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"pages\" in vars())\n",
    "assert(type(pages[0]) == type(pd.DataFrame()))\n",
    "assert(\"Feet\" in pages[0])\n",
    "assert(\"Range\" in pages[1])\n",
    "assert(\"Mountain\" in pages[2])\n",
    "assert(\"Location and Notes\" in pages[3])\n",
    "assert(\"Metres\" in pages[4])\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Joining the individual DataFrames into one large DataFrame\n",
    "\n",
    "Now that you have **ALL** of the tables in the `pages` variable, we want to convert this into one large DataFrame.  However, instead of having just one DataFrame, the webpage has different tables.\n",
    "\n",
    "Let's explore the individual tables.  Using `pages[0]`, you can view the first table of data found on the Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Using `pages[1]`, you view the second table that was found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finding the Last DataFrame\n",
    "\n",
    "Continue to look at the tables the Wikipedia page contains.  Find out the **last index** of `pages` that contains data amount the mountains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combining the DataFrames Together\n",
    "\n",
    "Before we can do analysis on the whole dataset, we need to join the individual tables together.  When we join DataFrames end-to-end, where the last row of the previous DataFrame is followed by the first row of the next DataFrame, the operation is called concatenation.\n",
    "\n",
    "Read the DISCOVERY guide to learn the syntax on \"Combining DataFrames by Concatenation\"\n",
    "- [Guide: \"Combining DataFrames by Concatenation\"](https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/) (https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/)\n",
    "\n",
    "Use concatenation to create a single DataFrame `df` that contains data amount every mountain found on the Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Checkpoint Tests 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Data Merging\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df\" in vars())\n",
    "assert(len(df) > len(pages[0]))\n",
    "assert(\"Feet\" in df)\n",
    "assert(\"Mountain\" in df)\n",
    "assert(df[\"Range\"].iloc[35] == \"Hindu Kush\")\n",
    "assert(df[\"Location and Notes\"].iloc[141] == \"Pakistan/Afghanistan\")\n",
    "assert(len(df) > 1500 and len(df) < 1650)\n",
    "assert(len(df[ df[\"Location and Notes\"].str.contains(\"Himalayas\")]) == 35)\n",
    "print(f\"{tada} All Tests Passed! {tada}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mountains in the United States\n",
    "\n",
    "Now that we have every mountain in a single DataFrame, we can do some analysis!  In the dataset, the `Location and Notes` column contains a human-written description of the location and other notes.\n",
    "\n",
    "Create a DataFrame called `df_us` that contains all of the mountains in the United States.\n",
    "\n",
    "- You will need to look back at the [Wikipedia page]((https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/)), or explore `df` here in Python, to find out all the different ways mountains in the United States might be labeled.  *(Hint: There's two different ways!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = ...\n",
    "df_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis: Percentage of Mountains in the Dataset in the United States?\n",
    "\n",
    "What percentage of mountains in the entire dataset is found in the United States?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_us = ...\n",
    "pct_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Checkpoint Tests 🔬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Mountains\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df_us\" in vars())\n",
    "assert(len(df_us) > 300 and len(df_us) < 400)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Mount Saint Elias\")]) == 1)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Denali\")]) == 1)\n",
    "assert(df_us[\"Feet\"].iloc[128] == 12326)\n",
    "assert(df_us[\"Feet\"].iloc[45] + df_us[\"Feet\"].iloc[33] == 28396)\n",
    "\n",
    "assert(\"pct_us\" in vars())\n",
    "assert(pct_us == len(df_us) / len(df))\n",
    "\n",
    "\n",
    "print(f\"{tada} DataFrame Analysis: All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 🔬 Microproject - All Checkpoint 🔬\n",
    "\n",
    "The final check is that you pass all the tests, all at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Final Checkpoint\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject. Even though you can modify this\n",
    "#   cell, you should treat it like it's a read-only cell since it will be replaced with\n",
    "#   a fresh version when your code is checked.\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you believe is\n",
    "#   actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"pages\" in vars())\n",
    "assert(type(pages[0]) == type(pd.DataFrame()))\n",
    "assert(\"Feet\" in pages[0])\n",
    "assert(\"Range\" in pages[1])\n",
    "assert(\"Mountain\" in pages[2])\n",
    "assert(\"Location and Notes\" in pages[3])\n",
    "assert(\"Metres\" in pages[4])\n",
    "\n",
    "assert(\"df\" in vars())\n",
    "assert(len(df) > len(pages[0]))\n",
    "assert(\"Feet\" in df)\n",
    "assert(\"Mountain\" in df)\n",
    "assert(df[\"Range\"].iloc[35] == \"Hindu Kush\")\n",
    "assert(df[\"Location and Notes\"].iloc[141] == \"Pakistan/Afghanistan\")\n",
    "assert(len(df) > 1500 and len(df) < 1650)\n",
    "assert(len(df[ df[\"Location and Notes\"].str.contains(\"Himalayas\")]) == 35)\n",
    "\n",
    "\n",
    "assert(\"df_us\" in vars())\n",
    "assert(len(df_us) > 300 and len(df_us) < 400)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Mount Saint Elias\")]) == 1)\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Denali\")]) == 1)\n",
    "assert(df_us[\"Feet\"].iloc[128] == 12326)\n",
    "assert(df_us[\"Feet\"].iloc[45] + df_us[\"Feet\"].iloc[33] == 28396)\n",
    "\n",
    "assert(\"pct_us\" in vars())\n",
    "assert(pct_us == len(df_us) / len(df))\n",
    "\n",
    "print(f\"{tada}{tada} All Tests Passed! {tada}{tada}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  ⚠️ **Make certain to save your work.** ⚠️ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and return to https://discovery.cs.illinois.edu/microproject/highest-mountain/ and complete the section **\"Commit and Grade Your Notebook\"**.\n",
    "\n",
    "3. If you see a 100% grade result on your GitHub Action, you've completed this MicroProject! 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
